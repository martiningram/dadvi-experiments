{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which run to use as a reference; set to None to use the one initially intended to be the reference.\n",
    "REFERENCE_ROW_INDEX = 1\n",
    "\n",
    "# Set this to the appropriate directory\n",
    "# The M_x means how many draws were used to run the experiments\n",
    "base_path = './coverage_warm_starts_rerun/M_64/'\n",
    "\n",
    "# Which model name to plot. Use \"ARM\" to analyse all ARM models.\n",
    "model_name = 'occ_det'\n",
    "\n",
    "coverage_runs = glob(join(base_path, '*', '*.pkl'))\n",
    "model_names = [x.split('/')[-2] for x in coverage_runs]\n",
    "assert(len(coverage_runs) > 0)\n",
    "\n",
    "rel_names = [model_name] if model_name != 'ARM' \\\n",
    "    else [x for x in model_names if x not in ['occ_det', 'tennis', 'microcredit', 'potus']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'filename': coverage_runs, 'model_name': model_names})\n",
    "\n",
    "# Drop the test models\n",
    "df = df[~df['model_name'].str.contains('test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_z_scores(loaded, reference_row_index=None, n_subset=None):\n",
    "    \n",
    "    if n_subset is not None:\n",
    "        # Pick only the first n_subset\n",
    "        loaded = loaded.iloc[:n_subset]\n",
    "    \n",
    "    if reference_row_index is not None:\n",
    "        # Change reference\n",
    "        reference_row = loaded.iloc[reference_row_index]\n",
    "        loaded = loaded.copy()\n",
    "                \n",
    "        other_rows = loaded.loc[[x for x in loaded.index if x != reference_row.name]].copy()\n",
    "        \n",
    "        # This is pretty dumb -- better way?\n",
    "        other_rows['reference_means'] = other_rows['reference_means'].apply(lambda _: reference_row['means'])\n",
    "        other_rows['reference_freq_sds'] = other_rows['freq_sds'].apply(lambda _: reference_row['freq_sds'])\n",
    "                \n",
    "        loaded = other_rows\n",
    "    \n",
    "    z_scores = loaded.apply(\n",
    "        lambda row: (row['means'] - row['reference_means']) / np.sqrt(\n",
    "            row['reference_freq_sds']**2 + row['freq_sds']**2),\n",
    "        axis=1)\n",
    "    \n",
    "    # Make them an array\n",
    "    z_array = np.stack(z_scores.values)\n",
    "    \n",
    "    return z_array\n",
    "\n",
    "def evaluate_z_scores(z_array, crit_prob=0.025):\n",
    "\n",
    "    z_crit = norm.ppf(crit_prob)\n",
    "    within_interval = np.abs(z_array) < np.abs(z_crit)\n",
    "    within_ratio = within_interval.mean()\n",
    "    \n",
    "    return within_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./coverage_warm_starts_rerun/M_64/radon_no_pool_chr/coverage_results.pkl\n"
     ]
    }
   ],
   "source": [
    "filename = df['filename'].iloc[0]\n",
    "print(filename)\n",
    "result = pd.read_pickle(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "Index(['means', 'seed', 'freq_sds', 'newton_step_norm', 'scipy_opt_result',\n",
      "       'reference_means', 'reference_freq_sds', 'M',\n",
      "       'reference_newton_step_norm', 'reference_scipy_opt_result'],\n",
      "      dtype='object')\n",
      "=======================\n",
      "\n",
      "0     64\n",
      "1     64\n",
      "2     64\n",
      "3     64\n",
      "4     64\n",
      "      ..\n",
      "95    64\n",
      "96    64\n",
      "97    64\n",
      "98    64\n",
      "99    64\n",
      "Name: M, Length: 100, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Looks like a single run is1000 different runs\n",
    "print(len(result['seed']))\n",
    "print(result.keys())\n",
    "\n",
    "print('=======================\\n')\n",
    "#print(result.iloc[2]['freq_sds'])\n",
    "print(result['M'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the actual pickled results\n",
    "df['loaded'] = df['filename'].apply(pd.read_pickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>means</th>\n",
       "      <th>seed</th>\n",
       "      <th>freq_sds</th>\n",
       "      <th>newton_step_norm</th>\n",
       "      <th>scipy_opt_result</th>\n",
       "      <th>reference_means</th>\n",
       "      <th>reference_freq_sds</th>\n",
       "      <th>M</th>\n",
       "      <th>reference_newton_step_norm</th>\n",
       "      <th>reference_scipy_opt_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[87.01123, 2.905291, 6.013665, 0.55783266]</td>\n",
       "      <td>1000</td>\n",
       "      <td>[0.1099612048616109, 0.004232627780388123, 0.2...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>{'x': [87.01123, 2.905291, 6.013665, 0.5578326...</td>\n",
       "      <td>[86.95640093045265, 2.897581366961627, 5.97447...</td>\n",
       "      <td>[0.11779586115094012, 0.00431034592793851, 0.2...</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'x': [86.9564, 2.8975813, 5.9744716, 0.559813...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[86.88435, 2.8961458, 5.932241, 0.5673275]</td>\n",
       "      <td>1001</td>\n",
       "      <td>[0.11009873405193897, 0.004292656800942259, 0....</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>{'x': [86.88435, 2.8961458, 5.932241, 0.567327...</td>\n",
       "      <td>[86.95640093045265, 2.897581366961627, 5.97447...</td>\n",
       "      <td>[0.11779586115094012, 0.00431034592793851, 0.2...</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'x': [86.9564, 2.8975813, 5.9744716, 0.559813...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[87.00213, 2.8992324, 5.7837462, 0.5744881]</td>\n",
       "      <td>1002</td>\n",
       "      <td>[0.11242536325121924, 0.004290984416831309, 0....</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>{'x': [87.00213, 2.8992324, 5.7837462, 0.57448...</td>\n",
       "      <td>[86.95640093045265, 2.897581366961627, 5.97447...</td>\n",
       "      <td>[0.11779586115094012, 0.00431034592793851, 0.2...</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'x': [86.9564, 2.8975813, 5.9744716, 0.559813...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[86.93819, 2.8927805, 6.268122, 0.57062894]</td>\n",
       "      <td>1003</td>\n",
       "      <td>[0.11032773838013536, 0.004178320985602901, 0....</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>{'x': [86.93819, 2.8927805, 6.268122, 0.570628...</td>\n",
       "      <td>[86.95640093045265, 2.897581366961627, 5.97447...</td>\n",
       "      <td>[0.11779586115094012, 0.00431034592793851, 0.2...</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'x': [86.9564, 2.8975813, 5.9744716, 0.559813...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[86.760765, 2.9056168, 5.761699, 0.559659]</td>\n",
       "      <td>1004</td>\n",
       "      <td>[0.10810466393770593, 0.004249855760150295, 0....</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>{'x': [86.760765, 2.9056168, 5.761699, 0.55965...</td>\n",
       "      <td>[86.95640093045265, 2.897581366961627, 5.97447...</td>\n",
       "      <td>[0.11779586115094012, 0.00431034592793851, 0.2...</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{'x': [86.9564, 2.8975813, 5.9744716, 0.559813...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         means  seed  \\\n",
       "0   [87.01123, 2.905291, 6.013665, 0.55783266]  1000   \n",
       "1   [86.88435, 2.8961458, 5.932241, 0.5673275]  1001   \n",
       "2  [87.00213, 2.8992324, 5.7837462, 0.5744881]  1002   \n",
       "3  [86.93819, 2.8927805, 6.268122, 0.57062894]  1003   \n",
       "4   [86.760765, 2.9056168, 5.761699, 0.559659]  1004   \n",
       "\n",
       "                                            freq_sds  newton_step_norm  \\\n",
       "0  [0.1099612048616109, 0.004232627780388123, 0.2...           0.00000   \n",
       "1  [0.11009873405193897, 0.004292656800942259, 0....           0.00000   \n",
       "2  [0.11242536325121924, 0.004290984416831309, 0....           0.00000   \n",
       "3  [0.11032773838013536, 0.004178320985602901, 0....           0.00001   \n",
       "4  [0.10810466393770593, 0.004249855760150295, 0....           0.00000   \n",
       "\n",
       "                                    scipy_opt_result  \\\n",
       "0  {'x': [87.01123, 2.905291, 6.013665, 0.5578326...   \n",
       "1  {'x': [86.88435, 2.8961458, 5.932241, 0.567327...   \n",
       "2  {'x': [87.00213, 2.8992324, 5.7837462, 0.57448...   \n",
       "3  {'x': [86.93819, 2.8927805, 6.268122, 0.570628...   \n",
       "4  {'x': [86.760765, 2.9056168, 5.761699, 0.55965...   \n",
       "\n",
       "                                     reference_means  \\\n",
       "0  [86.95640093045265, 2.897581366961627, 5.97447...   \n",
       "1  [86.95640093045265, 2.897581366961627, 5.97447...   \n",
       "2  [86.95640093045265, 2.897581366961627, 5.97447...   \n",
       "3  [86.95640093045265, 2.897581366961627, 5.97447...   \n",
       "4  [86.95640093045265, 2.897581366961627, 5.97447...   \n",
       "\n",
       "                                  reference_freq_sds   M  \\\n",
       "0  [0.11779586115094012, 0.00431034592793851, 0.2...  64   \n",
       "1  [0.11779586115094012, 0.00431034592793851, 0.2...  64   \n",
       "2  [0.11779586115094012, 0.00431034592793851, 0.2...  64   \n",
       "3  [0.11779586115094012, 0.00431034592793851, 0.2...  64   \n",
       "4  [0.11779586115094012, 0.00431034592793851, 0.2...  64   \n",
       "\n",
       "   reference_newton_step_norm  \\\n",
       "0                         0.0   \n",
       "1                         0.0   \n",
       "2                         0.0   \n",
       "3                         0.0   \n",
       "4                         0.0   \n",
       "\n",
       "                          reference_scipy_opt_result  \n",
       "0  {'x': [86.9564, 2.8975813, 5.9744716, 0.559813...  \n",
       "1  {'x': [86.9564, 2.8975813, 5.9744716, 0.559813...  \n",
       "2  {'x': [86.9564, 2.8975813, 5.9744716, 0.559813...  \n",
       "3  {'x': [86.9564, 2.8975813, 5.9744716, 0.559813...  \n",
       "4  {'x': [86.9564, 2.8975813, 5.9744716, 0.559813...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show some example data\n",
    "df['loaded'].iloc[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bit of explanation here: the field \"loaded\" now contains the rerun information. The column \"means\" lists the means for each rerun. The column \"reference_means\" lists the means for the reference run whose confidence interval we wish to evalute. And the column \"reference_freq_sds\" contains the estimated frequentist standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the worst final Newton step for all reruns\n",
    "df['worst_newton_step_norm'] = df['loaded'].apply(lambda x: x['newton_step_norm'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check convergence\n",
    "np.log10(df['worst_newton_step_norm']).hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop models that likely didn't converge\n",
    "print('Dropping:')\n",
    "print(df[df['worst_newton_step_norm'] > 10**(-2)]['model_name'])\n",
    "\n",
    "problematic =  df[df['worst_newton_step_norm'] >= 10**(-2)].copy()\n",
    "\n",
    "df = df[df['worst_newton_step_norm'] < 10**(-2)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also check scipy convergence message\n",
    "\n",
    "def compute_frac_non_convergent(loaded):\n",
    "    \n",
    "    #return np.mean(loaded['scipy_opt_result'].apply(lambda x: x.status) != 0)\n",
    "    return np.mean(loaded['scipy_opt_result'].apply(lambda x: x.message) != 'Optimization terminated successfully.')\n",
    "\n",
    "def drop_non_converged(loaded):\n",
    "    \n",
    "    #return loaded[loaded['scipy_opt_result'].apply(lambda x: x.status) == 0]\n",
    "    return loaded[loaded['scipy_opt_result'].apply(lambda x: x.message) == 'Optimization terminated successfully.']\n",
    "\n",
    "# Check scipy convergence statuses\n",
    "df['frac_not_converged'] = df['loaded'].apply(compute_frac_non_convergent)\n",
    "\n",
    "# Drop these\n",
    "df['loaded'] = df['loaded'].apply(drop_non_converged)\n",
    "\n",
    "# Subset to the model names desired\n",
    "df = df[df['model_name'].isin(rel_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['frac_not_converged'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['z_scores'] = df['loaded'].apply(partial(compute_z_scores, reference_row_index=REFERENCE_ROW_INDEX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['frac_within'] = df['z_scores'].apply(evaluate_z_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['M'] = df['loaded'].apply(lambda x: x['M'].iloc[0])\n",
    "\n",
    "df['M'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 95% should lie within.\n",
    "df[['model_name', 'M', 'frac_within']].sort_values('frac_within').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the z-scores into \"p-values\"\n",
    "df['p_vals'] = df['z_scores'].apply(norm.cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make them into one long vector\n",
    "all_p_vals = np.concatenate(df['p_vals'].apply(lambda x: x.reshape(-1)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a histogram\n",
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "_ = ax.hist(all_p_vals, density=True, bins=100)\n",
    "ax.axhline(1, color='r')\n",
    "\n",
    "f.set_size_inches(6, 4)\n",
    "f.tight_layout()\n",
    "\n",
    "#plt.savefig(f'overall_coverage_M={df[\"M\"].iloc[0]}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do a test to check for uniformity\n",
    "stats.kstest(all_p_vals, stats.uniform(loc=0.0, scale=1.0).cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can do the same test by model\n",
    "df.groupby('model_name').apply(\n",
    "    lambda df: stats.kstest(df['p_vals'].iloc[0].reshape(-1), stats.uniform(loc=0.0, scale=1.0).cdf)[1]).sort_values().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure this works as intended -- this one should not be rejected\n",
    "stats.kstest(norm.cdf(np.random.randn(1000)), stats.uniform(loc=0., scale=1.).cdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out a model of interest\n",
    "model_to_check = 'occ_det'\n",
    "\n",
    "model_p_vals = df[df['model_name'] == model_to_check]['p_vals'].iloc[0]\n",
    "model_p_vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['model_name'] == model_to_check]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['model_name'] == model_to_check].iloc[0]['loaded'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(model_p_vals.reshape(-1), density=True, bins=20)\n",
    "plt.axhline(1.)\n",
    "\n",
    "# plt.savefig(f'{model_to_check}_coverage_M={df[\"M\"].iloc[0]}.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_z_scores = df[df['model_name'] == model_to_check]['z_scores'].iloc[0].reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly, we can take a look at which z-score is most outlying\n",
    "df['min_z_score'] = df['z_scores'].apply(lambda x: x.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('min_z_score').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_one = df.sort_values('min_z_score').iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dadvi-experiments",
   "language": "python",
   "name": "dadvi-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6b81382af3beaebbac93aac606334308960b1a7270e498d25ccdd66c34d7f6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
