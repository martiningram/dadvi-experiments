{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import join\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def load_pickle_safely(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def maybe_load_pickle(pickle_file):\n",
    "    try:\n",
    "        result = load_pickle_safely(pickle_file)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def compute_means(draw_dict):\n",
    "    \n",
    "    return {x: y.mean(axis=(0, 1)) for x, y in draw_dict.items()}\n",
    "\n",
    "def compute_sds(draw_dict):\n",
    "    \n",
    "    return {x: y.std(axis=(0, 1)) for x, y in draw_dict.items()}\n",
    "\n",
    "def compute_z_score_mean(mean_dict, ref_mean_dict, ref_sd_dict):\n",
    "    \n",
    "    return {x: (mean_dict[x] - ref_mean_dict[x]) / ref_sd_dict[x] for x in mean_dict}\n",
    "\n",
    "def compute_relative_error_sd(sd_dict, ref_sd_dict):\n",
    "\n",
    "    return {x: (sd_dict[x] - ref_sd_dict[x]) / ref_sd_dict[x] for x in ref_sd_dict}\n",
    "\n",
    "def flatten_dict(var_dict, names):\n",
    "\n",
    "    return np.concatenate([var_dict[x].reshape(-1) for x in names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUTS ../blade_runs/nuts_results/\n",
      "DADVI ../blade_runs/dadvi_results/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LRVB ../blade_runs/lrvb_results/\n",
      "RAABBVI ../blade_runs/raabbvi_results/\n",
      "SADVI ../blade_runs/sadvi_results/\n",
      "SADVI_FR ../blade_runs/sfullrank_advi_results/\n",
      "LRVB_Doubling ../blade_runs/lrvb_doubling_results\n"
     ]
    }
   ],
   "source": [
    "from os.path import split, splitext\n",
    "\n",
    "def load_moment_df(draw_folder):\n",
    "\n",
    "    model_dicts = glob(join(draw_folder, \"draw_dicts\", \"*.npz\"))\n",
    "    data = pd.DataFrame({\"draw_dict_path\": model_dicts})\n",
    "\n",
    "    data[\"draws\"] = data[\"draw_dict_path\"].apply(lambda x: dict(np.load(x)))\n",
    "    data[\"means\"] = data[\"draws\"].apply(compute_means)\n",
    "    data[\"sds\"] = data[\"draws\"].apply(compute_sds)\n",
    "\n",
    "    # No need for the draws any more for now\n",
    "    data = data.drop(columns=\"draws\")\n",
    "\n",
    "    # Fetch model name\n",
    "    data['model_name'] = data['draw_dict_path'].apply(lambda x: splitext(split(x)[-1])[0])\n",
    "\n",
    "    return data\n",
    "\n",
    "def check_convergence_sadvi(metadata, max_iter=100000):\n",
    "\n",
    "    return metadata['steps'] < max_iter\n",
    "\n",
    "\n",
    "def check_convergence_raabbvi(metadata, max_iter=19900):\n",
    "\n",
    "    n_steps = metadata['kl_hist_i'].max()\n",
    "\n",
    "    return n_steps < max_iter\n",
    "\n",
    "\n",
    "def add_metadata(moment_df, method):\n",
    "\n",
    "    assert method in ['NUTS', 'RAABBVI', 'DADVI', 'LRVB', 'SADVI', 'SADVI_FR', 'LRVB_Doubling']\n",
    "\n",
    "    if method in ['RAABBVI', 'DADVI', 'LRVB', 'SADVI', 'SADVI_FR', 'LRVB_Doubling']:\n",
    "        subdir_lookup = {\n",
    "            'RAABBVI': 'info',\n",
    "            'DADVI': 'dadvi_info',\n",
    "            'LRVB': 'lrvb_info',\n",
    "            'SADVI': 'info',\n",
    "            'SADVI_FR': 'info',\n",
    "            'LRVB_Doubling': 'lrvb_info'\n",
    "        }\n",
    "        subdir = subdir_lookup[method]\n",
    "        moment_df[\"info_path\"] = (\n",
    "            moment_df[\"draw_dict_path\"]\n",
    "            .str.replace(\"draw_dicts\", subdir)\n",
    "            .str.replace(\".npz\", \".pkl\", regex=False)\n",
    "        )\n",
    "\n",
    "        moment_df['metadata'] = moment_df['info_path'].apply(load_pickle_safely)\n",
    "        moment_df['runtime'] = moment_df['metadata'].apply(lambda x: x['runtime'])\n",
    "\n",
    "        if method.startswith('SADVI'):\n",
    "            moment_df['converged'] = moment_df['metadata'].apply(check_convergence_sadvi)\n",
    "        elif method == 'RAABBVI':\n",
    "            moment_df['converged'] = moment_df['metadata'].apply(check_convergence_raabbvi)\n",
    "\n",
    "    else:\n",
    "        # It's NUTS; get runtime:\n",
    "        moment_df['runtime_path'] = (\n",
    "            moment_df['draw_dict_path']\n",
    "            .str.replace('draw_dicts', 'runtimes')\n",
    "            .str.replace('.npz', '.csv', regex=False)\n",
    "        )\n",
    "        moment_df['runtime'] = (\n",
    "            moment_df['runtime_path']\n",
    "            .apply(lambda x: pd.read_csv(x)['0'].iloc[0])\n",
    "        )\n",
    "\n",
    "        # TODO: get rhat\n",
    "\n",
    "    return moment_df\n",
    "\n",
    "from os.path import join\n",
    "\n",
    "base_folder = '../blade_runs/'\n",
    "\n",
    "folder_method_list = (\n",
    "    (join(base_folder, \"nuts_results/\"), 'NUTS'),\n",
    "    (join(base_folder, \"dadvi_results/\"), 'DADVI'),\n",
    "    (join(base_folder, \"lrvb_results/\"), 'LRVB'),\n",
    "    (join(base_folder, \"raabbvi_results/\"), 'RAABBVI'),\n",
    "    (join(base_folder, \"sadvi_results/\"), 'SADVI'),\n",
    "    (join(base_folder, \"sfullrank_advi_results/\"), 'SADVI_FR'),\n",
    "    (join(base_folder, 'lrvb_doubling_results'), 'LRVB_Doubling')\n",
    ")\n",
    "\n",
    "all_results = dict()\n",
    "\n",
    "for cur_folder, cur_method in folder_method_list:\n",
    "\n",
    "    print(cur_method, cur_folder)\n",
    "\n",
    "    data = load_moment_df(cur_folder)\n",
    "\n",
    "    data = add_metadata(data, cur_method)\n",
    "\n",
    "    all_results[cur_method] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_deviation_stats(model_df, reference_df):\n",
    "\n",
    "    together = model_df.merge(\n",
    "        reference_df, on=\"model_name\", suffixes=(\"_model\", \"_reference\")\n",
    "    )\n",
    "\n",
    "    together[\"mean_deviations\"] = together.apply(\n",
    "        lambda x: compute_z_score_mean(\n",
    "            x[\"means_model\"], x[\"means_reference\"], x[\"sds_reference\"]\n",
    "        ),\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    together[\"sd_deviations\"] = together.apply(\n",
    "        lambda x: compute_relative_error_sd(x[\"sds_model\"], x[\"sds_reference\"]), axis=1\n",
    "    )\n",
    "\n",
    "    together[\"var_names\"] = together[\"means_reference\"].apply(\n",
    "        lambda x: sorted(list(x.keys()))\n",
    "    )\n",
    "\n",
    "\n",
    "    # Add these to the model stats\n",
    "    cols_to_keep = [\n",
    "        \"model_name\",\n",
    "        \"mean_deviations\",\n",
    "        \"sd_deviations\",\n",
    "        \"var_names\",\n",
    "    ]\n",
    "\n",
    "    new_stats = together[cols_to_keep]\n",
    "\n",
    "    return model_df.merge(new_stats, on='model_name', how='left')\n",
    "\n",
    "\n",
    "def add_derived_stats(model_df):\n",
    "\n",
    "    model_df[\"mean_deviations_flat\"] = model_df.apply(\n",
    "        lambda x: flatten_dict(x[\"mean_deviations\"], x[\"var_names\"]), axis=1\n",
    "    )\n",
    "\n",
    "    model_df[\"sd_deviations_flat\"] = model_df.apply(\n",
    "        lambda x: flatten_dict(x[\"sd_deviations\"], x[\"var_names\"]), axis=1\n",
    "    )\n",
    "\n",
    "    model_df['mean_rms'] = model_df['mean_deviations_flat'].apply(lambda x: np.sqrt(np.mean(x**2)))\n",
    "    model_df['sd_rms'] = model_df['sd_deviations_flat'].apply(lambda x: np.sqrt(np.mean(x**2)))\n",
    "\n",
    "    return model_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['SADVI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raabbvi_maxiter = 19900\n",
    "\n",
    "method_1 = 'LRVB_Doubling'\n",
    "method_2 = 'RAABBVI'\n",
    "\n",
    "method_1_df = add_deviation_stats(all_results[method_1], all_results['NUTS']).dropna()\n",
    "method_1_df = add_derived_stats(method_1_df)\n",
    "\n",
    "method_2_df = add_deviation_stats(all_results[method_2], all_results['NUTS']).dropna()\n",
    "method_2_df = add_derived_stats(method_2_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['SADVI']['converged'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = method_1_df.merge(method_2_df, on='model_name', \n",
    "                                         suffixes=(f'_{method_1}', f'_{method_2}'))\n",
    "\n",
    "comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raabvi_with_deviations.iloc[0]['metadata'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "xmin, xmax = [comparison[f'mean_rms_{method_1}'].min(), comparison[f'mean_rms_{method_1}'].max()]\n",
    "# ax.scatter(comparison['mean_rms_raabbvi'], comparison['mean_rms_lrvb'], c=comparison['converged'])\n",
    "ax.scatter(comparison[f'mean_rms_{method_1}'], comparison[f'mean_rms_{method_2}'])\n",
    "ax.plot([xmin, xmax], [xmin, xmax])\n",
    "\n",
    "for row in comparison.itertuples():\n",
    "    ax.annotate(row.model_name, (getattr(row, f'mean_rms_{method_1}'), getattr(row, f'mean_rms_{method_2}')))\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel(f'RMSE mean scaled by posterior sd, {method_1}')\n",
    "ax.set_ylabel(f'RMSE mean scaled by posterior sd, {method_2}')\n",
    "\n",
    "ax.grid(alpha=0.5, linestyle='--')\n",
    "\n",
    "f.set_size_inches(12, 8)\n",
    "f.tight_layout()\n",
    "\n",
    "# plt.savefig('./mean_comparison.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "xmin, xmax = [comparison[f'sd_rms_{method_1}'].min(), comparison[f'sd_rms_{method_1}'].max()]\n",
    "# ax.scatter(comparison['mean_rms_raabbvi'], comparison['mean_rms_lrvb'], c=comparison['converged'])\n",
    "ax.scatter(comparison[f'sd_rms_{method_1}'], comparison[f'sd_rms_{method_2}'])\n",
    "ax.plot([xmin, xmax], [xmin, xmax])\n",
    "\n",
    "for row in comparison.itertuples():\n",
    "    ax.annotate(row.model_name, (getattr(row, f'sd_rms_{method_1}'), getattr(row, f'sd_rms_{method_2}')))\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel(f'RMSE sd scaled by posterior sd, {method_1}')\n",
    "ax.set_ylabel(f'RMSE sd scaled by posterior sd, {method_2}')\n",
    "\n",
    "ax.grid(alpha=0.5, linestyle='--')\n",
    "\n",
    "f.set_size_inches(12, 8)\n",
    "f.tight_layout()\n",
    "\n",
    "# plt.savefig('./sd_comparison.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "xmin, xmax = [comparison[f'runtime_{method_1}'].min(), comparison[f'runtime_{method_1}'].max()]\n",
    "# ax.scatter(comparison['mean_rms_raabbvi'], comparison['mean_rms_lrvb'], c=comparison['converged'])\n",
    "ax.scatter(comparison[f'runtime_{method_1}'], comparison[f'runtime_{method_2}'])\n",
    "ax.plot([xmin, xmax], [xmin, xmax])\n",
    "\n",
    "for row in comparison.itertuples():\n",
    "    ax.annotate(row.model_name, (getattr(row, f'runtime_{method_1}'), getattr(row, f'runtime_{method_2}')))\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel(f'Runtime, {method_1}')\n",
    "ax.set_ylabel(f'Runtime, {method_2}')\n",
    "\n",
    "ax.grid(alpha=0.5, linestyle='--')\n",
    "\n",
    "f.set_size_inches(12, 8)\n",
    "f.tight_layout()\n",
    "\n",
    "# plt.savefig('runtime_comparison.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['LRVB_Doubling']['M'] = all_results['LRVB_Doubling']['metadata'].apply(lambda x: x['M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['LRVB_Doubling'][['model_name', 'runtime', 'M']].sort_values('M', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results['LRVB'][['model_name', 'runtime']].sort_values('runtime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dadvi-experiments",
   "language": "python",
   "name": "dadvi-experiments"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "d6b81382af3beaebbac93aac606334308960b1a7270e498d25ccdd66c34d7f6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
